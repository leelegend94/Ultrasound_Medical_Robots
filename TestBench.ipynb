{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  torch.Size([1, 256, 256])\n",
      "range:  tensor(0.7333)\n"
     ]
    }
   ],
   "source": [
    "image_path = \"/home/eadu/workspace/us_robot/DataSet/SimDatasetTest2/0031/image.png\"\n",
    "image = Image.open(image_path)\n",
    "resize_to = [256,256]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize(resize_to),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0.5,0.5)\n",
    "        ])\n",
    "    \n",
    "img = transform(image)\n",
    "print(\"shape: \", img.shape)\n",
    "print(\"max pixel value: \", torch.max(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Vector Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = torch.Tensor([[1,0,0],[0,1,0],[-1,0,0],[0,-1,0],[1,0,1],[0,1,1],[-1,0,1],[0,-1,1]]).view([8,3,1])\n",
    "n1 = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "n2 = torch.randn(1, requires_grad=True, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radi(n):\n",
    "    return sum([(Data[i,0]*n[1]-Data[i,1]*n[0])**2+(Data[i,1]*n[2]-Data[i,2]*n[1])**2+(Data[i,2]*n[0]-Data[i,0]*n[2])**2  for i in range(Data.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.RMSprop([n1,n2],lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.9682], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radi([n1,n2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  -1.0140439006959531e-25 0.0 1\n"
     ]
    }
   ],
   "source": [
    "for ep in range(50):\n",
    "    #print(\"ep\",ep)\n",
    "    optim.zero_grad()\n",
    "    loss = radi([n1,n2,1])\n",
    "    #print(loss)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "print(\"n = \",n1.item(),n2.item(),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.5564e-16], requires_grad=True) tensor([1.1065e-29], requires_grad=True) 1\n"
     ]
    }
   ],
   "source": [
    "print(n1,n2,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
